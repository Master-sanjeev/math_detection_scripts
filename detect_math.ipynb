{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb73e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 13:47:22.602407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-12 13:47:22.602516: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import collections\n",
    "# Set headless-friendly backend.\n",
    "import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
    "import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import six\n",
    "from six.moves import range\n",
    "from six.moves import zip\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from object_detection.core import keypoint_ops\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.utils import shape_utils\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "   # Suppress Matplotlib warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b55b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "_TITLE_LEFT_MARGIN = 10\n",
    "_TITLE_TOP_MARGIN = 10\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743a87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    instance_masks=None,\n",
    "    instance_boundaries=None,\n",
    "    keypoints=None,\n",
    "    keypoint_scores=None,\n",
    "    keypoint_edges=None,\n",
    "    track_ids=None,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black',\n",
    "    skip_boxes=False,\n",
    "    skip_scores=False,\n",
    "    skip_labels=False,\n",
    "    skip_track_ids=False):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\n",
    "  This function groups boxes that correspond to the same location\n",
    "  and creates a display string for each detection and overlays these\n",
    "  on the image. Note that this function modifies the image in place, and returns\n",
    "  that same image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    instance_masks: a uint8 numpy array of shape [N, image_height, image_width],\n",
    "      can be None.\n",
    "    instance_boundaries: a numpy array of shape [N, image_height, image_width]\n",
    "      with values ranging between 0 and 1, can be None.\n",
    "    keypoints: a numpy array of shape [N, num_keypoints, 2], can\n",
    "      be None.\n",
    "    keypoint_scores: a numpy array of shape [N, num_keypoints], can be None.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    track_ids: a numpy array of shape [N] with unique track ids. If provided,\n",
    "      color-coding of boxes will be determined by these ids, and not the class\n",
    "      indices.\n",
    "    use_normalized_coordinates: whether boxes is to be interpreted as\n",
    "      normalized coordinates or not.\n",
    "    max_boxes_to_draw: maximum number of boxes to visualize.  If None, draw\n",
    "      all boxes.\n",
    "    min_score_thresh: minimum score threshold for a box or keypoint to be\n",
    "      visualized.\n",
    "    agnostic_mode: boolean (default: False) controlling whether to evaluate in\n",
    "      class-agnostic mode or not.  This mode will display scores but ignore\n",
    "      classes.\n",
    "    line_thickness: integer (default: 4) controlling line width of the boxes.\n",
    "    mask_alpha: transparency value between 0 and 1 (default: 0.4).\n",
    "    groundtruth_box_visualization_color: box color for visualizing groundtruth\n",
    "      boxes\n",
    "    skip_boxes: whether to skip the drawing of bounding boxes.\n",
    "    skip_scores: whether to skip score when drawing a single detection\n",
    "    skip_labels: whether to skip label when drawing a single detection\n",
    "    skip_track_ids: whether to skip track id when drawing a single detection\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3) with overlaid boxes.\n",
    "  \"\"\"\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_instance_masks_map = {}\n",
    "  box_to_instance_boundaries_map = {}\n",
    "  box_to_keypoints_map = collections.defaultdict(list)\n",
    "  box_to_keypoint_scores_map = collections.defaultdict(list)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if instance_masks is not None:\n",
    "        box_to_instance_masks_map[box] = instance_masks[i]\n",
    "      if instance_boundaries is not None:\n",
    "        box_to_instance_boundaries_map[box] = instance_boundaries[i]\n",
    "      if keypoints is not None:\n",
    "        box_to_keypoints_map[box].extend(keypoints[i])\n",
    "      if keypoint_scores is not None:\n",
    "        box_to_keypoint_scores_map[box].extend(keypoint_scores[i])\n",
    "      if track_ids is not None:\n",
    "        box_to_track_ids_map[box] = track_ids[i]\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not skip_labels:\n",
    "          if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name)\n",
    "        if not skip_scores:\n",
    "          if not display_str:\n",
    "            display_str = '{}%'.format(round(100*scores[i]))\n",
    "          else:\n",
    "            display_str = '{}: {}%'.format(display_str, round(100*scores[i]))\n",
    "        if not skip_track_ids and track_ids is not None:\n",
    "          if not display_str:\n",
    "            display_str = 'ID {}'.format(track_ids[i])\n",
    "          else:\n",
    "            display_str = '{}: ID {}'.format(display_str, track_ids[i])\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        elif track_ids is not None:\n",
    "          prime_multipler = _get_multiplier_for_color_randomness()\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              (prime_multipler * track_ids[i]) % len(STANDARD_COLORS)]\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "#   count = 0\n",
    "#   for box, color in box_to_color_map.items():\n",
    "#     ymin, xmin, ymax, xmax = box\n",
    "# #     print(\"Box \", count, xmin, ymin, xmax, ymax)\n",
    "#     count += 1\n",
    "#     if instance_masks is not None:\n",
    "#       draw_mask_on_image_array(\n",
    "#           image,\n",
    "#           box_to_instance_masks_map[box],\n",
    "#           color=color,\n",
    "#           alpha=mask_alpha\n",
    "#       )\n",
    "#     if instance_boundaries is not None:\n",
    "#       draw_mask_on_image_array(\n",
    "#           image,\n",
    "#           box_to_instance_boundaries_map[box],\n",
    "#           color='red',\n",
    "#           alpha=1.0\n",
    "#       )\n",
    "#     draw_bounding_box_on_image_array(\n",
    "#         image,\n",
    "#         ymin,\n",
    "#         xmin,\n",
    "#         ymax,\n",
    "#         xmax,\n",
    "#         color=color,\n",
    "#         thickness=0 if skip_boxes else line_thickness,\n",
    "#         display_str_list=box_to_display_str_map[box],\n",
    "#         use_normalized_coordinates=use_normalized_coordinates)\n",
    "#     if keypoints is not None:\n",
    "#       keypoint_scores_for_box = None\n",
    "#       if box_to_keypoint_scores_map:\n",
    "#         keypoint_scores_for_box = box_to_keypoint_scores_map[box]\n",
    "#       draw_keypoints_on_image_array(\n",
    "#           image,\n",
    "#           box_to_keypoints_map[box],\n",
    "#           keypoint_scores_for_box,\n",
    "#           min_score_thresh=min_score_thresh,\n",
    "#           color=color,\n",
    "#           radius=line_thickness / 2,\n",
    "#           use_normalized_coordinates=use_normalized_coordinates,\n",
    "#           keypoint_edges=keypoint_edges,\n",
    "#           keypoint_edge_color=color,\n",
    "#           keypoint_edge_width=line_thickness // 2)\n",
    "    \n",
    "  print('num boxes : ', len(box_to_color_map))\n",
    "\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c2f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mask_on_image_array(image, mask, color='red', alpha=0.4):\n",
    "  \"\"\"Draws mask on an image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_height, 3)\n",
    "    mask: a uint8 numpy array of shape (img_height, img_height) with\n",
    "      values between either 0 or 1.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    alpha: transparency value between 0 and 1. (default: 0.4)\n",
    "  Raises:\n",
    "    ValueError: On incorrect data type for image or masks.\n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    raise ValueError('`image` not of type np.uint8')\n",
    "  if mask.dtype != np.uint8:\n",
    "    raise ValueError('`mask` not of type np.uint8')\n",
    "  if image.shape[:2] != mask.shape:\n",
    "    raise ValueError('The image has spatial dimensions %s but the mask has '\n",
    "                     'dimensions %s' % (image.shape[:2], mask.shape))\n",
    "  rgb = ImageColor.getrgb(color)\n",
    "  pil_image = Image.fromarray(image)\n",
    "\n",
    "  solid_color = np.expand_dims(\n",
    "      np.ones_like(mask), axis=2) * np.reshape(list(rgb), [1, 1, 3])\n",
    "  pil_solid_color = Image.fromarray(np.uint8(solid_color)).convert('RGBA')\n",
    "  pil_mask = Image.fromarray(np.uint8(255.0*alpha*(mask > 0))).convert('L')\n",
    "  pil_image = Image.composite(pil_solid_color, pil_image, pil_mask)\n",
    "  np.copyto(image, np.array(pil_image.convert('RGB')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e33610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image (numpy array).\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44cc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image_array(image,\n",
    "                                  keypoints,\n",
    "                                  keypoint_scores=None,\n",
    "                                  min_score_thresh=0.5,\n",
    "                                  color='red',\n",
    "                                  radius=2,\n",
    "                                  use_normalized_coordinates=True,\n",
    "                                  keypoint_edges=None,\n",
    "                                  keypoint_edge_color='green',\n",
    "                                  keypoint_edge_width=2):\n",
    "  \"\"\"Draws keypoints on an image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    keypoint_scores: a numpy array with shape [num_keypoints]. If provided, only\n",
    "      those keypoints with a score above score_threshold will be visualized.\n",
    "    min_score_thresh: A scalar indicating the minimum keypoint score required\n",
    "      for a keypoint to be visualized. Note that keypoint_scores must be\n",
    "      provided for this threshold to take effect.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    keypoint_edge_color: color to draw the keypoint edges with. Default is red.\n",
    "    keypoint_edge_width: width of the edges drawn between keypoints. Default\n",
    "      value is 2.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_keypoints_on_image(image_pil,\n",
    "                          keypoints,\n",
    "                          keypoint_scores=keypoint_scores,\n",
    "                          min_score_thresh=min_score_thresh,\n",
    "                          color=color,\n",
    "                          radius=radius,\n",
    "                          use_normalized_coordinates=use_normalized_coordinates,\n",
    "                          keypoint_edges=keypoint_edges,\n",
    "                          keypoint_edge_color=keypoint_edge_color,\n",
    "                          keypoint_edge_width=keypoint_edge_width)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553890ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image.\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Each string in display_str_list is displayed on a separate line above the\n",
    "  bounding box in black text on a rectangle filled with the input 'color'.\n",
    "  If the top of the bounding box extends to the edge of the image, the strings\n",
    "  are displayed below the bounding box.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', 24)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba868be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image(image,\n",
    "                            keypoints,\n",
    "                            keypoint_scores=None,\n",
    "                            min_score_thresh=0.5,\n",
    "                            color='red',\n",
    "                            radius=2,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            keypoint_edges=None,\n",
    "                            keypoint_edge_color='green',\n",
    "                            keypoint_edge_width=2):\n",
    "  \"\"\"Draws keypoints on an image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    keypoint_scores: a numpy array with shape [num_keypoints].\n",
    "    min_score_thresh: a score threshold for visualizing keypoints. Only used if\n",
    "      keypoint_scores is provided.\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "    keypoint_edges: A list of tuples with keypoint indices that specify which\n",
    "      keypoints should be connected by an edge, e.g. [(0, 1), (2, 4)] draws\n",
    "      edges from keypoint 0 to 1 and from keypoint 2 to 4.\n",
    "    keypoint_edge_color: color to draw the keypoint edges with. Default is red.\n",
    "    keypoint_edge_width: width of the edges drawn between keypoints. Default\n",
    "      value is 2.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  keypoints = np.array(keypoints)\n",
    "  keypoints_x = [k[1] for k in keypoints]\n",
    "  keypoints_y = [k[0] for k in keypoints]\n",
    "  if use_normalized_coordinates:\n",
    "    keypoints_x = tuple([im_width * x for x in keypoints_x])\n",
    "    keypoints_y = tuple([im_height * y for y in keypoints_y])\n",
    "  if keypoint_scores is not None:\n",
    "    keypoint_scores = np.array(keypoint_scores)\n",
    "    valid_kpt = np.greater(keypoint_scores, min_score_thresh)\n",
    "  else:\n",
    "    valid_kpt = np.where(np.any(np.isnan(keypoints), axis=1),\n",
    "                         np.zeros_like(keypoints[:, 0]),\n",
    "                         np.ones_like(keypoints[:, 0]))\n",
    "  valid_kpt = [v for v in valid_kpt]\n",
    "\n",
    "  for keypoint_x, keypoint_y, valid in zip(keypoints_x, keypoints_y, valid_kpt):\n",
    "    if valid:\n",
    "      draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n",
    "                    (keypoint_x + radius, keypoint_y + radius)],\n",
    "                   outline=color, fill=color)\n",
    "  if keypoint_edges is not None:\n",
    "    for keypoint_start, keypoint_end in keypoint_edges:\n",
    "      if (keypoint_start < 0 or keypoint_start >= len(keypoints) or\n",
    "          keypoint_end < 0 or keypoint_end >= len(keypoints)):\n",
    "        continue\n",
    "      if not (valid_kpt[keypoint_start] and valid_kpt[keypoint_end]):\n",
    "        continue\n",
    "      edge_coordinates = [\n",
    "          keypoints_x[keypoint_start], keypoints_y[keypoint_start],\n",
    "          keypoints_x[keypoint_end], keypoints_y[keypoint_end]\n",
    "      ]\n",
    "      draw.line(\n",
    "          edge_coordinates, fill=keypoint_edge_color, width=keypoint_edge_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d3e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_multiplier_for_color_randomness():\n",
    "  \"\"\"Returns a multiplier to get semi-random colors from successive indices.\n",
    "  This function computes a prime number, p, in the range [2, 17] that:\n",
    "  - is closest to len(STANDARD_COLORS) / 10\n",
    "  - does not divide len(STANDARD_COLORS)\n",
    "  If no prime numbers in that range satisfy the constraints, p is returned as 1.\n",
    "  Once p is established, it can be used as a multiplier to select\n",
    "  non-consecutive colors from STANDARD_COLORS:\n",
    "  colors = [(p * i) % len(STANDARD_COLORS) for i in range(20)]\n",
    "  \"\"\"\n",
    "  num_colors = len(STANDARD_COLORS)\n",
    "  prime_candidates = [5, 7, 11, 13, 17]\n",
    "\n",
    "  # Remove all prime candidates that divide the number of colors.\n",
    "  prime_candidates = [p for p in prime_candidates if num_colors % p]\n",
    "  if not prime_candidates:\n",
    "    return 1\n",
    "\n",
    "  # Return the closest prime number to num_colors / 10.\n",
    "  abs_distance = [np.abs(num_colors / 10. - p) for p in prime_candidates]\n",
    "  num_candidates = len(abs_distance)\n",
    "  inds = [i for _, i in sorted(zip(abs_distance, range(num_candidates)))]\n",
    "  return prime_candidates[inds[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9715f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 32.86048197746277 seconds\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_MODEL_DIR = '/home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/workspace/train/exported-models/frcnn'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = '/home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/workspace/train/annotations/label_map.pbtxt'\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# LOAD LABEL MAP DATA FOR PLOTTING\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff78173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/16.png... \n",
      "Inference time :  19.91287875175476 seconds\n",
      "num detections :  100\n",
      "num boxes :  6\n",
      "Done\n",
      "Visualise time :  0.0432276725769043 seconds\n",
      "Write time :  0.45511603355407715 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/10.png... \n",
      "Inference time :  20.488703966140747 seconds\n",
      "num detections :  100\n",
      "num boxes :  38\n",
      "Done\n",
      "Visualise time :  0.07869362831115723 seconds\n",
      "Write time :  0.4595508575439453 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/6.png... \n",
      "Inference time :  19.81977677345276 seconds\n",
      "num detections :  100\n",
      "num boxes :  23\n",
      "Done\n",
      "Visualise time :  0.0345613956451416 seconds\n",
      "Write time :  0.4356205463409424 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/1.png... \n",
      "Inference time :  20.72623896598816 seconds\n",
      "num detections :  100\n",
      "num boxes :  55\n",
      "Done\n",
      "Visualise time :  0.0603334903717041 seconds\n",
      "Write time :  0.4646122455596924 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/11.png... \n",
      "Inference time :  20.07648730278015 seconds\n",
      "num detections :  100\n",
      "num boxes :  40\n",
      "Done\n",
      "Visualise time :  0.03668403625488281 seconds\n",
      "Write time :  0.45939087867736816 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/15.png... \n",
      "Inference time :  19.64916181564331 seconds\n",
      "num detections :  100\n",
      "num boxes :  48\n",
      "Done\n",
      "Visualise time :  0.03203320503234863 seconds\n",
      "Write time :  0.466998815536499 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/5.png... \n",
      "Inference time :  20.655483961105347 seconds\n",
      "num detections :  100\n",
      "num boxes :  4\n",
      "Done\n",
      "Visualise time :  0.03502917289733887 seconds\n",
      "Write time :  0.43544626235961914 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/8.png... \n",
      "Inference time :  21.912322998046875 seconds\n",
      "num detections :  100\n",
      "num boxes :  21\n",
      "Done\n",
      "Visualise time :  0.06746888160705566 seconds\n",
      "Write time :  0.5059564113616943 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/3.png... \n",
      "Inference time :  20.07536292076111 seconds\n",
      "num detections :  100\n",
      "num boxes :  42\n",
      "Done\n",
      "Visualise time :  0.08057045936584473 seconds\n",
      "Write time :  0.44925689697265625 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/13.png... \n",
      "Inference time :  20.53863024711609 seconds\n",
      "num detections :  100\n",
      "num boxes :  17\n",
      "Done\n",
      "Visualise time :  0.07884359359741211 seconds\n",
      "Write time :  0.43210554122924805 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/0.png... \n",
      "Inference time :  20.700270175933838 seconds\n",
      "num detections :  100\n",
      "num boxes :  34\n",
      "Done\n",
      "Visualise time :  0.07470059394836426 seconds\n",
      "Write time :  0.45530080795288086 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/14.png... \n",
      "Inference time :  19.918598651885986 seconds\n",
      "num detections :  100\n",
      "num boxes :  10\n",
      "Done\n",
      "Visualise time :  0.03372073173522949 seconds\n",
      "Write time :  0.43395090103149414 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/4.png... \n",
      "Inference time :  19.82953906059265 seconds\n",
      "num detections :  100\n",
      "num boxes :  6\n",
      "Done\n",
      "Visualise time :  0.043474674224853516 seconds\n",
      "Write time :  0.4152193069458008 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/2.png... \n",
      "Inference time :  20.349401712417603 seconds\n",
      "num detections :  100\n",
      "num boxes :  23\n",
      "Done\n",
      "Visualise time :  0.07430410385131836 seconds\n",
      "Write time :  0.44335365295410156 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/9.png... \n",
      "Inference time :  20.476475954055786 seconds\n",
      "num detections :  100\n",
      "num boxes :  28\n",
      "Done\n",
      "Visualise time :  0.06183171272277832 seconds\n",
      "Write time :  0.5090513229370117 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/7.png... \n",
      "Inference time :  21.708215475082397 seconds\n",
      "num detections :  100\n",
      "num boxes :  29\n",
      "Done\n",
      "Visualise time :  0.04462575912475586 seconds\n",
      "Write time :  0.4577174186706543 seconds\n",
      "Running inference for /home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images/12.png... \n",
      "Inference time :  20.16270422935486 seconds\n",
      "num detections :  100\n",
      "num boxes :  18\n",
      "Done\n",
      "Visualise time :  0.0372014045715332 seconds\n",
      "Write time :  0.4451277256011963 seconds\n"
     ]
    }
   ],
   "source": [
    "map = {1:8, 2:98}\n",
    "# raw_detections = None\n",
    "IMAGES_PATH = \"/home/sanjeev/projects/mtp-1/TFOD_FRCNN(1)/TFOD/images\" \n",
    "\n",
    "output_path = os.path.join(\"/\".join(IMAGES_PATH.split('/')[:-1]), 'output')\n",
    "if not os.path.exists(output_path) :\n",
    "    os.mkdir(os.path.join(output_path))\n",
    "    \n",
    "  \n",
    "for IMAGE_PATH in os.listdir(IMAGES_PATH):\n",
    "  start = time.time()\n",
    "  img = IMAGE_PATH\n",
    "  IMAGE_PATH = os.path.join(IMAGES_PATH, IMAGE_PATH)\n",
    "  print('Running inference for {}... '.format(IMAGE_PATH))\n",
    "\n",
    "  image = cv2.imread(IMAGE_PATH)\n",
    "#   image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#   image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "  # input_tensor = np.expand_dims(image_np, 0)\n",
    "  detections = detect_fn(input_tensor)\n",
    "#   raw_detections = detections.copy()\n",
    "    \n",
    "  end = time.time()\n",
    "\n",
    "  print(\"Inference time : \", end-start, \"seconds\")\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "\n",
    "  start = time.time()\n",
    "  num_detections = int(detections.pop('num_detections'))\n",
    "  print('num detections : ',num_detections)\n",
    "  detections = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in detections.items()}\n",
    "  detections['num_detections'] = num_detections\n",
    "  # print(\"printing detections : \"+str(detections))\n",
    "  # detection_classes should be ints.\n",
    "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "  # print(detections)\n",
    "  image_with_detections = image.copy()\n",
    "  arr = []\n",
    "  for num in detections['detection_classes']:\n",
    "    arr.append(map[num])\n",
    "  # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "  visualize_boxes_and_labels_on_image_array(\n",
    "        image_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        track_ids=np.asarray(arr),\n",
    "        max_boxes_to_draw=None,\n",
    "        min_score_thresh=0.8,\n",
    "        agnostic_mode=False,\n",
    "        line_thickness=12)\n",
    "\n",
    "  print('Done')\n",
    "  end = time.time()\n",
    "  print(\"Visualise time : \", end-start, \"seconds\")\n",
    "  # DISPLAYS OUTPUT IMAGE\n",
    "#   cv2_imshow(image_with_detections)\n",
    "#   cv2.imshow(\"detection\", image_with_detections)\n",
    "#   cv2.waitKey(0) \n",
    "  \n",
    "  #closing all open windows \n",
    "#   cv2.destroyAllWindows() \n",
    "  cv2.imwrite(os.path.join(output_path, img), image_with_detections)\n",
    "  print(\"Write time : \", time.time()-end, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810a850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
